{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitscarletcondafa9e397948a143f4ade5ba17d10d2306",
   "display_name": "Python 3.8.3 64-bit ('scarlet': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# $\\text{Morpheus}^{++}$ Label Idea\n",
    "\n",
    "The input, $x$, to $\\text{Morpheus}^{++}$ is a multiband image with a height $H$, width $W$, and number of bands $B$\n",
    "\n",
    "$$x_{ijb} \\in \\mathbb{R}^{H \\times W \\times B}$$\n",
    "\n",
    "The label has three components:\n",
    "- Morphology $\\mathbb{R}^{1}$\n",
    "- claim vectors, $\\mathbb{Z}^{B \\times 8 \\times 2}$\n",
    "- claim distribution, $\\mathbb{Z}^{B \\times 8}$ \n",
    "- Centerpoint distribution value $\\mathbb{R}^{1}$\n",
    "\n",
    "The first component, morphology, is given by the original morpheus setup.\n",
    "\n",
    "The claim vectors and claim distribution are new to morpheus and describe deblending\n",
    "\n",
    "The center of mass distribution value represents whether or not that pixels is a center of mass indicating an instance which the claim vectors and claim distribtution point to\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Center of Mass Distribution\n",
    "\n",
    "The center of mass distribution indicates individual instances in the image. In https://arxiv.org/pdf/1911.10194.pdf, during training, the center of masses are encoded as a gaussian with standard deviation of 8 pixels.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import starmap\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "#https://stackoverflow.com/a/46892763/2691018\n",
    "def gaussian_kernel_2d(kernlen, std=8):\n",
    "    \"\"\"Returns a 2D Gaussian kernel array.\"\"\"\n",
    "    gkern1d = signal.gaussian(kernlen, std=std).reshape(kernlen, 1)\n",
    "    gkern2d = np.outer(gkern1d, gkern1d)\n",
    "    return gkern2d\n",
    "\n",
    "\n",
    "# UPDATES 'image' in place\n",
    "def insert_gaussian(image, g_kern, y, x) -> None:\n",
    "    height, width = image.shape\n",
    "    half_kernel_len = g_kern.shape[0] // 2\n",
    "\n",
    "    def image_slice_f(yx, bound):\n",
    "        return slice(\n",
    "            max(yx-half_kernel_len, 0),\n",
    "            min(yx+half_kernel_len, bound)\n",
    "        )\n",
    "\n",
    "    def kernel_slice_f(yx, bound):\n",
    "        begin = half_kernel_len - min(\n",
    "            half_kernel_len, \n",
    "            half_kernel_len-(half_kernel_len-yx)\n",
    "        )\n",
    "\n",
    "        end = half_kernel_len + min(\n",
    "            half_kernel_len,\n",
    "            bound - yx\n",
    "        ) \n",
    "        return slice(begin, end)\n",
    "\n",
    "    image_ys = image_slice_f(y, height)\n",
    "    image_xs = image_slice_f(x, width)\n",
    "\n",
    "    kernel_ys = kernel_slice_f(y, height)\n",
    "    kernel_xs = kernel_slice_f(x, width)\n",
    "\n",
    "    tmp_image = image[image_ys, image_xs].copy()\n",
    "    tmp_kernel = g_kern[kernel_ys, kernel_xs].copy()\n",
    "\n",
    "    image[image_ys, image_xs] = np.maximum(tmp_image, tmp_kernel)\n",
    "\n",
    "\n",
    "\n",
    "# source_locations is a 2d array indicating source locations\n",
    "def build_center_mass_image(\n",
    "    source_locations:np.ndarray,\n",
    "    gaussian_kernel_std:int,\n",
    ") -> np.ndarray:\n",
    "    center_of_mass = np.zeros_like(source_locations, dtype=np.float32)\n",
    "    src_ys, src_xs = np.nonzero(source_locations)\n",
    "\n",
    "    width, height = center_of_mass.shape\n",
    "\n",
    "    gaussian_kernel = gaussian_kernel_2d(width, std=gaussian_kernel_std)\n",
    "\n",
    "    insert_gaussian_f = partial(insert_gaussian, center_of_mass, gaussian_kernel)\n",
    "\n",
    "    for _ in starmap(insert_gaussian_f, zip(src_ys, src_xs)):pass\n",
    "\n",
    "    return center_of_mass"
   ]
  },
  {
   "source": [
    "## Claim Vector\n",
    "\n",
    "Unlike in https://arxiv.org/pdf/1911.10194.pdf, where each pixel is associated with a single instance. In our setting, each pixel can be associated with multiple intances. This is encoded by considering each pixel as an 8-connected pixel where each pixel in the 8-connected set encodes an xy offset to its nearest center of mass. Enoding the data this way allows a pixel to be associated with at most 8 different sources.\n",
    "\n",
    "## Claim Map\n",
    "\n",
    "Each source associated with a pixel via a claim vector only contributes some fraction\n",
    "of the flux in the image. To incorporate that information into the claim map is a \n",
    "vector weights that sum to one that indicate how much of the flux comes from a single\n",
    "source."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, List, Tuple\n",
    "\n",
    "import scarlet\n",
    "import scarlet.psf as psf\n",
    "\n",
    "def get_scarlet_source(\n",
    "    model_frame,\n",
    "    observation,\n",
    "    morpheus_label:np.ndarray, \n",
    "    segmap:np.ndarray,\n",
    "    source_id:int, \n",
    "    source_yx: Tuple[int, int]\n",
    ") -> scarlet.component.FactorizedComponent:\n",
    "    # For now go with the default scarlet recommendation of ExtendedSource with k=1\n",
    "    return scarlet.ExtendedSource(model_frame, source_yx, observation)\n",
    "\n",
    "\n",
    "def get_scarlet_fit(\n",
    "    filters:List[str], \n",
    "    psfs:np.ndarray, \n",
    "    model_psf:Callable, \n",
    "    flux:np.ndarray, # [b, h, w]\n",
    "    source_locations: np.ndarray,\n",
    "    morpheus_label:np.ndarray, # [h, w, m]\n",
    "    segmap:np.ndarray # [h, w]\n",
    "):\n",
    "    \"\"\"Fit scarlet to image for generating labels\"\"\"\n",
    "\n",
    "\n",
    "    model_frame = scarlet.Frame(\n",
    "        flux.shape,\n",
    "        psfs=model_psf,\n",
    "        channels=filters\n",
    "    )\n",
    "\n",
    "    observation = scarlet.Observation(\n",
    "        images,\n",
    "        psfs=psfs,\n",
    "        weights=weights,\n",
    "        channels=filters,\n",
    "    ).match(model_frame)\n",
    "\n",
    "    get_source = partial(\n",
    "        get_scarlet_source, \n",
    "        model_frame, \n",
    "        observation, \n",
    "        morpheus_label, \n",
    "        segmap\n",
    "    )\n",
    "\n",
    "    src_ys, src_xs = np.nonzero(source_locations)\n",
    "    src_ids = source_locations[src_ys, src_xs]\n",
    "\n",
    "    sources = list(starmap(get_source, src_ids, zip(src_ys, src_xs)))\n",
    "\n",
    "    blend = scarlet.Blend(sources, observation)\n",
    "    blend.fit(200, e_rel = 1.e-6)\n",
    "\n",
    "    def render_source(obs, src):\n",
    "        return obs.render(src.get_model(frame=src.frame))\n",
    "    render_f = partial(render_source, observation)\n",
    "\n",
    "    model_src_vals = list(map(render_f, sources))\n",
    "    \n",
    "    return model_src_vals\n",
    "\n",
    "def get_claim_vector_image_and_map(\n",
    "    source_locations:np.ndarray, \n",
    "    bhw:Tuple[int, int, int],\n",
    "    model_src_vals:List[np.ndarray],\n",
    "):\n",
    "    \n",
    "    # Updates claim_vector_image and claim_map_image in place\n",
    "    def single_pixel_vector(\n",
    "        claim_vector_image:np.ndarray,\n",
    "        claim_map_image:np.ndarray,\n",
    "        centers:np.ndarray, \n",
    "        i:int, \n",
    "        j:int, \n",
    "        b: int\n",
    "    ) -> None:\n",
    "        connected_idxs = list(product([i, i-1, i+1], [j, j-1, j+1]))\n",
    "        connected_idxs.remove((i, j))\n",
    "        connected_array = np.array(connected_idxs)        \n",
    "\n",
    "        ijb_src_flux = np.array([m[b,i,j] for m in model_src_vals])\n",
    "        ijb_src_flux_mask = ijb_src_flux > 0\n",
    "        \n",
    "        ijb_normed_src_flux = (\n",
    "            (ijb_src_flux * ijb_src_flux_mask) \n",
    "            / (ijb_src_flux * ijb_src_flux_mask).sum()\n",
    "        )\n",
    "\n",
    "        def closest_center(\n",
    "            centers:np.array, \n",
    "            flux_mask:np.ndarray, \n",
    "            idx:np.ndarray\n",
    "        ):\n",
    "            dist = np.linalg.norm(centers-idx, axis=1)\n",
    "            masked_dist = np.where(flux_mask, dist, np.inf)\n",
    "            return centers[np.argmin(masked_dist)]\n",
    "\n",
    "        closest_f = partial(closest_center, centers, ijb_src_flux_mask)\n",
    "        closest_sources = np.array(list(map(closest_f, connected_array)))\n",
    "        claim_vector = connected_array - closest_sources # [8]\n",
    "\n",
    "        claim_vector_image[i, j, b, ...] = claim_vector\n",
    "\n",
    "        def convert_to_claim_map(\n",
    "            centers:np.ndarray, \n",
    "            normed_flux:np.ndarray, \n",
    "            src:np.ndarray\n",
    "        ):\n",
    "            return ((src==centers).all(axis=1).astype(np.float32) * normed_f_ijb).sum()\n",
    "\n",
    "        convert_to_map_f = partial(convert_to_claim_map, centers, ijb_normed_src_flux)\n",
    "        raw_claim_map = np.array(list(map(convert_to_map_f, closest_sources)))\n",
    "        claim_map = raw_claim_map / raw_claim_map.sum()\n",
    "\n",
    "        claim_map_image[i, j, b, ...] = claim_map\n",
    "\n",
    "\n",
    "    n_bands, height, width = bhw\n",
    "    claim_vector_image = np.zeros([height, width, n_bands, 8, 2], dtype=np.float32)\n",
    "    claim_map_image = np.zeros([height, width, n_bands, 8], dtype=np.float)\n",
    "\n",
    "    src_ys, src_xs = np.nonzero(source_locations)\n",
    "    centers = np.array([src_ys, src_xs]).T # [n, 2]\n",
    "\n",
    "    single_pixel_f = partial(\n",
    "        single_pixel_vector, \n",
    "        claim_vector_image, \n",
    "        claim_map_image, \n",
    "        centers\n",
    "    )\n",
    "\n",
    "    idxs = tqdm(\n",
    "        product(range(height), range(width), range(n_bands)),\n",
    "        total=height * width * n_bands,\n",
    "        unit=\"pixels\" \n",
    "    )\n",
    "\n",
    "    for _ in starmap(single_pixel_f, idxs): pass\n",
    "    \n",
    "    return claim_vector_image, claim_map_image"
   ]
  },
  {
   "source": [
    "## Label Function\n",
    "\n",
    "Given a single image containing a flux image, source label, and source locations we can create a label\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ]
}