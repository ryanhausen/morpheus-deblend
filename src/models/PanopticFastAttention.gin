# MIT License
# Copyright 2020 Ryan Hausen
#
# Permission is hereby granted, free of charge, to any person obtaining a copy of
# this software and associated documentation files (the "Software"), to deal in
# the Software without restriction, including without limitation the rights to
# use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
# the Software, and to permit persons to whom the Software is furnished to do so,
# subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
# CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

import gin.tf.external_configurables
import src.features.data_provider
import src.models.losses
import src.models.metric_logging
import src.models.PanopticFastAttention
import src.models.train_model

# tensorflow vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
# tf.keras.losses_utils.ReductionV2.NONE == "none"
tf.keras.optimizers.Adam.learning_rate = 0.00001
tf.keras.losses.BinaryCrossentropy.from_logits = True
tf.keras.losses.BinaryCrossentropy.reduction = "none"
tf.keras.losses.CategoricalCrossentropy.from_logits = True
tf.keras.losses.CategoricalCrossentropy.reduction = "none"
tf.keras.losses.MeanAbsoluteError.reduction = "none"
tf.keras.losses.MeanSquaredError.reduction = "none"
# tensorflow ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


# src.features.data_provider vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
# src.features.data_provider.augment.jitter = False
# src.features.data_provider.augment.flip_y = False
# src.features.data_provider.augment.flip_x = False
# src.features.data_provider.augment.normalize = False

src.features.data_provider.get_dataset.batch_size = 16
src.features.data_provider.get_dataset.instance_mode = "v4"
# src.features.data_provider ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


# src.models.losses vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
tf.nn.compute_average_loss.global_batch_size = 32

src.models.losses.semantic_loss.loss_object = @tf.keras.losses.BinaryCrossentropy()
src.models.losses.semantic_loss.avg = @tf.nn.compute_average_loss

src.models.losses.claim_vector_loss.loss_object = @tf.keras.losses.MeanAbsoluteError()
src.models.losses.claim_vector_loss.avg = @tf.nn.compute_average_loss

src.models.losses.discrete_claim_vector_loss.loss_object = @tf.keras.losses.MeanAbsoluteError()
src.models.losses.discrete_claim_vector_loss.avg = @tf.nn.compute_average_loss

src.models.losses.claim_map_loss.loss_object = @tf.keras.losses.CategoricalCrossentropy()
src.models.losses.claim_map_loss.avg = @tf.nn.compute_average_loss

src.models.losses.center_of_mass_loss.loss_object = @tf.keras.losses.MeanSquaredError()
src.models.losses.center_of_mass_loss.avg = @tf.nn.compute_average_loss

src.models.losses.loss_function.lambda_semantic = 2
src.models.losses.loss_function.lambda_claim_vector = 0.1
src.models.losses.loss_function.lambda_claim_map = 1
src.models.losses.loss_function.lambda_center_of_mass = 100
src.models.losses.loss_function.instance_mode = "v4"

# src.models.losses ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

# !!!!!!!!!!!!!!! The above and below lambda values should match !!!!!!!!!!!!!!!

# src.models.metric_logging vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
src.models.metric_logging.update_metrics.lambda_semantic = 2
src.models.metric_logging.update_metrics.lambda_claim_vector = 0.1
src.models.metric_logging.update_metrics.lambda_claim_map = 1
src.models.metric_logging.update_metrics.lambda_center_of_mass = 100
src.models.metric_logging.update_metrics.instance_mode = "v4"
# src.models.metric_logging ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


# src.models.PanopticFastAttention vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
src.models.PanopticFastAttention.get_model.input_shape = [256, 256, 4]
src.models.PanopticFastAttention.get_model.instance_mode = "v4"

src.models.PanopticFastAttention.encoder.input_shape = [256, 256, 4]
src.models.PanopticFastAttention.encoder.filters = [32, 64, 128, 256]

src.models.PanopticFastAttention.semantic_decoder.output_shape = [256, 256, 4]
src.models.PanopticFastAttention.semantic_decoder.filters = [32, 64, 128, 256]
src.models.PanopticFastAttention.semantic_decoder.n_classes = 1

src.models.PanopticFastAttention.instance_decoder.output_shape = [256, 256, 4]
src.models.PanopticFastAttention.instance_decoder.filters = [32, 64, 128, 256]

src.models.PanopticFastAttention.instance_decoder_v2.output_shape = [256, 256, 4]
src.models.PanopticFastAttention.instance_decoder_v2.filters = [32, 64, 128, 256]
src.models.PanopticFastAttention.instance_decoder_v2.n = 5

src.models.PanopticFastAttention.instance_decoder_v3.output_shape = [256, 256, 4]
src.models.PanopticFastAttention.instance_decoder_v3.filters = [32, 64, 128, 256]
# src.models.PanopticFastAttention ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^


# src.models.train_model vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv
__main__.training_func.model = @src.models.PanopticFastAttention.get_model
__main__.training_func.optimizer = @tf.keras.optimizers.Adam
__main__.training_func.metric_func = @src.models.metric_logging.update_metrics
__main__.training_func.checkpoint_dir = "../../models"
__main__.training_func.epochs = 2000
__main__.training_func.log_metric_batch_idx = 10
__main__.training_func.model_code_file = "PanopticFastAttention.py"
__main__.training_func.comet_disabled = True
__main__.training_func.experiment_project_name = "morpheus-deblend"
__main__.training_func.experiment_key = None

__main__.step.loss_func = @src.models.losses.loss_function
